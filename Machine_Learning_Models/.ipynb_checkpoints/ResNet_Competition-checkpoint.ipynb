{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aW0TlH62bhE"
   },
   "source": [
    "# Deep Residual Learning for Audio Recogniton <br>\n",
    "\n",
    "Author: Jamie McQuire <br>\n",
    "\n",
    "* This notebook is for the full competition dataset.\n",
    "* This notebook is going to implement a ResNet network for the classifiation of the spectrogram images.\n",
    "* This [tutorial](https://www.youtube.com/watch?v=wqkc-sj5H94) helped build the model.\n",
    "* This model will be trained using the image data from the pre-processing notebook.\n",
    "* Upload this notebook to google colab for faster computing with a GPU.\n",
    "* If you wish to repeat this analysis please upload the notebook to google drive (directories must be set appropriately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J16yO1CH4xlO"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GCBVDvE2mL5"
   },
   "source": [
    "* Mount the google drive where you should have the data stored.\n",
    "* Alternatively load the data into your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uYl3DOJ54_Mf",
    "outputId": "7295a419-b0dd-4c88-dd69-2819b8288260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-vd25Wa2pLr"
   },
   "source": [
    "* Load in the training and validation data from the pre-processing notebook.\n",
    "* Set your directories for reproducible analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfO38cst5CR9"
   },
   "outputs": [],
   "source": [
    "#load in the training data and labels\n",
    "X_train = np.load(\"/content/drive/My Drive/competition_data/X_train.npy\")\n",
    "Y_train = np.load(\"/content/drive/My Drive/competition_data/Y_train.npy\")\n",
    "\n",
    "#load in the validation data and labels\n",
    "X_val = np.load(\"/content/drive/My Drive/competition_data/X_val.npy\")\n",
    "Y_val = np.load(\"/content/drive/My Drive/competition_data/Y_val.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCKIsQ1q2vE0"
   },
   "source": [
    "* These are the default settings.\n",
    "* Check that the image_size = (161,99,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "smXeRTeU5J7r",
    "outputId": "4810e116-6f48-47b0-e5b5-6c0b6fee38e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 99, 1)\n"
     ]
    }
   ],
   "source": [
    "#default settings used\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "image_size = X_train.shape[1:]\n",
    "output_size = 12\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLP9H8OP2yS9"
   },
   "source": [
    "* Scale the image pixels for the deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXfCI9Lh5MT_"
   },
   "outputs": [],
   "source": [
    "#scale the X data\n",
    "X_train_scaled = X_train * (1 / 255)\n",
    "X_val_scaled = X_val * (1  / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98RYkRsg22VX"
   },
   "source": [
    "* Convert the labels to one-hot-encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTw6CyLX5PlE"
   },
   "outputs": [],
   "source": [
    "#one-hot encode the Y data\n",
    "Y_train = keras.utils.to_categorical(Y_train.astype(np.int),output_size)\n",
    "Y_val = keras.utils.to_categorical(Y_val.astype(np.int),output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9p28oppr26rA"
   },
   "source": [
    "* Function to define the architecture of the identity block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzex0NJV5S7w"
   },
   "outputs": [],
   "source": [
    "#building the identity block of the ResNet\n",
    "\n",
    "def identity_block(X,f,filters,stage,block):\n",
    "    \n",
    "    #this is the function for the identity block\n",
    "    #X is the input tensor\n",
    "    #f is the filter shape for the middle block\n",
    "    #filters is the list containing the filter sizes (int)\n",
    "    #stage names the layer relative to the position in the network\n",
    "    #block is used to name the layers \n",
    "    \n",
    "    #name definition\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    #filters 1,2,3\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    #initial value\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #define the first component block \n",
    "    X = Conv2D(filters=f1, kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2a\",kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base + \"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #second component block \n",
    "    X = Conv2D(filters=f2, kernel_size=(f,f),strides=(1,1),padding=\"same\",name=conv_name_base+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base + \"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #third component block \n",
    "    X = Conv2D(filters=f3,kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base + \"2c\")(X)\n",
    "    \n",
    "    #make the connection at the add block \n",
    "    X = Add()([X,X_shortcut])\n",
    "    #finish with the relu activation layer\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #return the new value of X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmgFQIOs3BVT"
   },
   "source": [
    "* Function to define the architecture of the convolutional block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnafLsZ55WfZ"
   },
   "outputs": [],
   "source": [
    "def convolution_block(X,f,filters,stage,block,s=2):\n",
    "    \n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    #initialize the value of X\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #the branch from the main path\n",
    "    X_filt3 = Conv2D(f3,(1,1),strides=(s,s),name=conv_name_base+\"1\",kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_filt3 = BatchNormalization(axis=3,name=bn_name_base + \"1\")(X_filt3)\n",
    "    \n",
    "    #main path\n",
    "    \n",
    "    #block 1\n",
    "    X = Conv2D(f1,kernel_size=(1,1),strides=(s,s),name=conv_name_base+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #block 2\n",
    "    X = Conv2D(f2,kernel_size=(f,f),strides=(1,1),padding=\"same\",name=conv_name_base+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #block 3\n",
    "    X = Conv2D(f3,kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    #add the branch and the main path together\n",
    "    X = Add()([X,X_filt3])\n",
    "    \n",
    "    #finish with a relu\n",
    "    X = Activation(\"relu\")(X) \n",
    "    \n",
    "    #return the new value of X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TP0JYspz3E7H"
   },
   "source": [
    "* Function to define the architecture of the ResNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6z4mish5ZOo"
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(161,99,1), num_classes=6):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #padding\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    #stage1\n",
    "    X = Conv2D(128, (7,7),strides=(2,2),name=\"conv1\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((3,3),strides=(2,2))(X)\n",
    "\n",
    "    X = Dropout(0.25)(X)\n",
    "    \n",
    "    #stage2\n",
    "    X = convolution_block(X,f=3,filters=[64,64,256],stage=2,s=1,block=\"a\")\n",
    "    X = identity_block(X,f=3,filters=[64,64,256],stage=2,block=\"b\")\n",
    "    X = identity_block(X,f=3,filters=[64,64,256],stage=2,block=\"c\")\n",
    "\n",
    "    X = Dropout(0.25)(X)\n",
    "    \n",
    "    #stage3\n",
    "    X = convolution_block(X,f=3,filters=[128,128,512],stage=3,s=2,block=\"a\")\n",
    "    X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"b\")\n",
    "    X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"c\")\n",
    "    X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"d\")\n",
    "\n",
    "    X = Dropout(0.25)(X)\n",
    "\n",
    "    #stage4\n",
    "    X = convolution_block(X,f=3,filters=[256,256,1024],stage=4,s=2,block=\"a\")\n",
    "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"b\")\n",
    "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"c\")\n",
    "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"d\")\n",
    "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"e\")\n",
    "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"f\")\n",
    "\n",
    "    X = Dropout(0.25)(X)\n",
    "    \n",
    "    #stage5\n",
    "    X = convolution_block(X,f=3,filters=[512,512,2048],stage=5,s=2,block=\"a\")\n",
    "    X = identity_block(X,f=3,filters=[512,512,2048],stage=5,block=\"b\")\n",
    "    X = identity_block(X,f=3,filters=[512,512,2048],stage=5,block=\"c\")\n",
    "    \n",
    "    X = Dropout(0.25)(X)\n",
    "\n",
    "    #stage6\n",
    "    X = AveragePooling2D(pool_size=(2,2),name=\"avg_pool\")(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(num_classes,activation=\"softmax\",name=\"fc\"+str(num_classes))(X)\n",
    "    \n",
    "    model = Model(inputs=X_input,outputs=X,name=\"ResNet50\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZ9JzA5k3Jav"
   },
   "source": [
    "* Generate the model and compile it.\n",
    "* Summary should provide information about the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJJfmZFY5bvD"
   },
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(161,99,1),num_classes=12)\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJ_LeCO33N2-"
   },
   "source": [
    "* Generate the class weights.\n",
    "* This is needed as the unknown category contains significantly more files than the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN50W7o55fIo"
   },
   "outputs": [],
   "source": [
    "Y_integers = np.argmax(Y_train, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(Y_integers), Y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1i8LHsxJ3Wb6"
   },
   "source": [
    "* Train the deep learning model over the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxcM7u3D5n7E"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled,Y_train,epochs=20,validation_data=(X_val_scaled,Y_val),\n",
    "                    batch_size=128,shuffle=True,class_weight=d_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpOugnlK3ZTP"
   },
   "source": [
    "* Save the model to your working directory.\n",
    "* This will prevent you from having to restart training incase of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaCBS1Cyt4WX"
   },
   "outputs": [],
   "source": [
    "model.save(\"ResNet_Trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPabqeXY3fn_"
   },
   "source": [
    "* If you do not need to reload the model you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQ9pdGb-vjYN"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Trained_Models/ResNet_Trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCK955RJ3kUI"
   },
   "source": [
    "* Code to plot the accuracy of the training and validation sets during model training.\n",
    "* Will save to a PDF figure in the working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQaxBZUERS-l"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='bottom right')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"CNN_fvocab_acc.pdf\",bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpbmNvzc3pe4"
   },
   "source": [
    "* Code to plot the loss of the training and validation sets during model training.\n",
    "* Will save to a PDF figure in the working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45dAZdAqRWuA"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"CNN_fvocab_loss.pdf\",bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gXQd_fX3rVP"
   },
   "source": [
    "* Load in part of the testing data that is generated in the pre-processing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPWYM0yvxIz_"
   },
   "outputs": [],
   "source": [
    "X1 = np.load(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/X_test_p1.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuUUVpb43zCC"
   },
   "source": [
    "* Scale the pixels of the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d23gnvvdzkXu"
   },
   "outputs": [],
   "source": [
    "X1 = X1 * (1/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cB4t1s7I31Rk"
   },
   "source": [
    "* Make predictions using the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIw1JLPRxmfr"
   },
   "outputs": [],
   "source": [
    "predict_1 = model.predict(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAv5Nxj135V1"
   },
   "source": [
    "* Repeat for the other parts of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWZnQKiZ296X"
   },
   "outputs": [],
   "source": [
    "#X1 = 0 to free up memory \n",
    "X1 = 0\n",
    "X2 = np.load(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/X_test_p2.npy\")\n",
    "X2 = X2 * (1/255)\n",
    "predict_2 = model.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTtCxphf3H9i"
   },
   "outputs": [],
   "source": [
    "#X2 = 0 to free up memory \n",
    "X2 = 0\n",
    "X3 = np.load(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/X_test_p3.npy\")\n",
    "X3 = X3 * (1/255)\n",
    "predict_3 = model.predict(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Znfv5YS-4CJ0"
   },
   "source": [
    "* Load in the .csv file for the filenames as a pandas dataframe.\n",
    "* This should contain the filenames for the testing data.\n",
    "* This is created in the testing pre-processing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uTkTe3w6s_u"
   },
   "outputs": [],
   "source": [
    "output_data = pd.read_csv(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/filenames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7yO24Fr4O7p"
   },
   "source": [
    "* Convert the predictions from the model to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me_IWGKu7yNr"
   },
   "outputs": [],
   "source": [
    "predicted_class1 = np.argmax(predict_1,axis=1)\n",
    "predicted_class2 = np.argmax(predict_2,axis=1)\n",
    "predicted_class3 = np.argmax(predict_3,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvQ4D_Z_4UDs"
   },
   "source": [
    "* Create a dictionary to map the labels to the correct voice command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ce3WpbBAAFDv"
   },
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    0 : \"yes\",\n",
    "    1 : \"no\",\n",
    "    2 : \"up\",\n",
    "    3 : \"down\",\n",
    "    4 : \"left\",\n",
    "    5 : \"right\",\n",
    "    6 : \"on\",\n",
    "    7 : \"off\",\n",
    "    8 : \"stop\",\n",
    "    9 : \"go\",\n",
    "    10 : \"silence\",\n",
    "    11 : \"unknown\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Zt3nOpp4Y2w"
   },
   "source": [
    "* Map the labels to the correct voice command.\n",
    "* Join the lists together to get the full list of predicted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dijOdT8AzAn"
   },
   "outputs": [],
   "source": [
    "predicted_class_labels1 = [label_dict[k] for k in predicted_class1]\n",
    "predicted_class_labels2 = [label_dict[k] for k in predicted_class2]\n",
    "predicted_class_labels3 = [label_dict[k] for k in predicted_class3]\n",
    "\n",
    "predicted_class_label = predicted_class_labels1 + predicted_class_labels2 + predicted_class_labels3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NutbvGG4gag"
   },
   "source": [
    "* Create a new column in the dataframe called \"label\" which we will fill with the predicted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p61dYl0y7kuB"
   },
   "outputs": [],
   "source": [
    "output_data[\"label\"] = np.nan\n",
    "\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GX60iHS4mSG"
   },
   "source": [
    "* Fill the \"label\" column with the predicted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwvpmAL9CElo"
   },
   "outputs": [],
   "source": [
    "predicted_class_array = np.asarray(predicted_class_label)\n",
    "print(predicted_class_array)\n",
    "\n",
    "output_data[\"label\"] = predicted_class_array\n",
    "\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9WfGSQs4rat"
   },
   "source": [
    "* Remove the unamed axis from the filename.csv dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpoTS5uKDw9Q"
   },
   "outputs": [],
   "source": [
    "output_data = output_data.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMf1baqo4vVz"
   },
   "source": [
    "* Check that the output is in the form of the Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjLFQHvLE_OV"
   },
   "outputs": [],
   "source": [
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLRJJpBH4yvQ"
   },
   "source": [
    "* Export the output to a .csv file ensuring that index=False.\n",
    "* The file is now ready for submission to Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAqlx3zJELNz"
   },
   "outputs": [],
   "source": [
    "output_data.to_csv(\"submission_resnet.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet_Competition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
