{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aW0TlH62bhE",
        "colab_type": "text"
      },
      "source": [
        "# Deep Residual Learning for Audio Recogniton <br>\n",
        "\n",
        "Author: Jamie McQuire <br>\n",
        "\n",
        "* This notebook is for the full competition dataset.\n",
        "* This notebook is going to implement a ResNet network for the classifiation of the spectrogram images.\n",
        "* This [tutorial](https://www.youtube.com/watch?v=wqkc-sj5H94) helped build the model.\n",
        "* This model will be trained using the image data from the pre-processing notebook.\n",
        "* Upload this notebook to google colab for faster computing with a GPU.\n",
        "* If you wish to repeat this analysis please upload the notebook to google drive (directories must be set appropriately)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J16yO1CH4xlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\n",
        "from keras.models import Model, load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GCBVDvE2mL5",
        "colab_type": "text"
      },
      "source": [
        "* Mount the google drive where you should have the data stored.\n",
        "* Alternatively load the data into your working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYl3DOJ54_Mf",
        "colab_type": "code",
        "outputId": "7295a419-b0dd-4c88-dd69-2819b8288260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-vd25Wa2pLr",
        "colab_type": "text"
      },
      "source": [
        "* Load in the training and validation data from the pre-processing notebook.\n",
        "* Set your directories for reproducible analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfO38cst5CR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load in the training data and labels\n",
        "X_train = np.load(\"/content/drive/My Drive/competition_data/X_train.npy\")\n",
        "Y_train = np.load(\"/content/drive/My Drive/competition_data/Y_train.npy\")\n",
        "\n",
        "#load in the validation data and labels\n",
        "X_val = np.load(\"/content/drive/My Drive/competition_data/X_val.npy\")\n",
        "Y_val = np.load(\"/content/drive/My Drive/competition_data/Y_val.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCKIsQ1q2vE0",
        "colab_type": "text"
      },
      "source": [
        "* These are the default settings.\n",
        "* Check that the image_size = (161,99,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smXeRTeU5J7r",
        "colab_type": "code",
        "outputId": "4810e116-6f48-47b0-e5b5-6c0b6fee38e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#default settings used\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "image_size = X_train.shape[1:]\n",
        "output_size = 12\n",
        "print(image_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(161, 99, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLP9H8OP2yS9",
        "colab_type": "text"
      },
      "source": [
        "* Scale the image pixels for the deep learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXfCI9Lh5MT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale the X data\n",
        "X_train_scaled = X_train * (1 / 255)\n",
        "X_val_scaled = X_val * (1  / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98RYkRsg22VX",
        "colab_type": "text"
      },
      "source": [
        "* Convert the labels to one-hot-encoded vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTw6CyLX5PlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one-hot encode the Y data\n",
        "Y_train = keras.utils.to_categorical(Y_train.astype(np.int),output_size)\n",
        "Y_val = keras.utils.to_categorical(Y_val.astype(np.int),output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p28oppr26rA",
        "colab_type": "text"
      },
      "source": [
        "* Function to define the architecture of the identity block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzex0NJV5S7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the identity block of the ResNet\n",
        "\n",
        "def identity_block(X,f,filters,stage,block):\n",
        "    \n",
        "    #this is the function for the identity block\n",
        "    #X is the input tensor\n",
        "    #f is the filter shape for the middle block\n",
        "    #filters is the list containing the filter sizes (int)\n",
        "    #stage names the layer relative to the position in the network\n",
        "    #block is used to name the layers \n",
        "    \n",
        "    #name definition\n",
        "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
        "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
        "    \n",
        "    #filters 1,2,3\n",
        "    f1, f2, f3 = filters\n",
        "    \n",
        "    #initial value\n",
        "    X_shortcut = X\n",
        "    \n",
        "    #define the first component block \n",
        "    X = Conv2D(filters=f1, kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2a\",kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=bn_name_base + \"2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #second component block \n",
        "    X = Conv2D(filters=f2, kernel_size=(f,f),strides=(1,1),padding=\"same\",name=conv_name_base+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=bn_name_base + \"2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #third component block \n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=bn_name_base + \"2c\")(X)\n",
        "    \n",
        "    #make the connection at the add block \n",
        "    X = Add()([X,X_shortcut])\n",
        "    #finish with the relu activation layer\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #return the new value of X\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmgFQIOs3BVT",
        "colab_type": "text"
      },
      "source": [
        "* Function to define the architecture of the convolutional block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnafLsZ55WfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolution_block(X,f,filters,stage,block,s=2):\n",
        "    \n",
        "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
        "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
        "    \n",
        "    f1, f2, f3 = filters\n",
        "    \n",
        "    #initialize the value of X\n",
        "    X_shortcut = X\n",
        "    \n",
        "    #the branch from the main path\n",
        "    X_filt3 = Conv2D(f3,(1,1),strides=(s,s),name=conv_name_base+\"1\",kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_filt3 = BatchNormalization(axis=3,name=bn_name_base + \"1\")(X_filt3)\n",
        "    \n",
        "    #main path\n",
        "    \n",
        "    #block 1\n",
        "    X = Conv2D(f1,kernel_size=(1,1),strides=(s,s),name=conv_name_base+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #block 2\n",
        "    X = Conv2D(f2,kernel_size=(f,f),strides=(1,1),padding=\"same\",name=conv_name_base+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    #block 3\n",
        "    X = Conv2D(f3,kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
        "    \n",
        "    #add the branch and the main path together\n",
        "    X = Add()([X,X_filt3])\n",
        "    \n",
        "    #finish with a relu\n",
        "    X = Activation(\"relu\")(X) \n",
        "    \n",
        "    #return the new value of X\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP0JYspz3E7H",
        "colab_type": "text"
      },
      "source": [
        "* Function to define the architecture of the ResNet model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6z4mish5ZOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape=(161,99,1), num_classes=6):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    #padding\n",
        "    X = ZeroPadding2D((3,3))(X_input)\n",
        "    \n",
        "    #stage1\n",
        "    X = Conv2D(128, (7,7),strides=(2,2),name=\"conv1\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name=\"bn_conv1\")(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    X = MaxPooling2D((3,3),strides=(2,2))(X)\n",
        "\n",
        "    X = Dropout(0.25)(X)\n",
        "    \n",
        "    #stage2\n",
        "    X = convolution_block(X,f=3,filters=[64,64,256],stage=2,s=1,block=\"a\")\n",
        "    X = identity_block(X,f=3,filters=[64,64,256],stage=2,block=\"b\")\n",
        "    X = identity_block(X,f=3,filters=[64,64,256],stage=2,block=\"c\")\n",
        "\n",
        "    X = Dropout(0.25)(X)\n",
        "    \n",
        "    #stage3\n",
        "    X = convolution_block(X,f=3,filters=[128,128,512],stage=3,s=2,block=\"a\")\n",
        "    X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"b\")\n",
        "    X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"c\")\n",
        "    X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"d\")\n",
        "\n",
        "    X = Dropout(0.25)(X)\n",
        "\n",
        "    #stage4\n",
        "    X = convolution_block(X,f=3,filters=[256,256,1024],stage=4,s=2,block=\"a\")\n",
        "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"b\")\n",
        "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"c\")\n",
        "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"d\")\n",
        "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"e\")\n",
        "    X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"f\")\n",
        "\n",
        "    X = Dropout(0.25)(X)\n",
        "    \n",
        "    #stage5\n",
        "    X = convolution_block(X,f=3,filters=[512,512,2048],stage=5,s=2,block=\"a\")\n",
        "    X = identity_block(X,f=3,filters=[512,512,2048],stage=5,block=\"b\")\n",
        "    X = identity_block(X,f=3,filters=[512,512,2048],stage=5,block=\"c\")\n",
        "    \n",
        "    X = Dropout(0.25)(X)\n",
        "\n",
        "    #stage6\n",
        "    X = AveragePooling2D(pool_size=(2,2),name=\"avg_pool\")(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(num_classes,activation=\"softmax\",name=\"fc\"+str(num_classes))(X)\n",
        "    \n",
        "    model = Model(inputs=X_input,outputs=X,name=\"ResNet50\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ9JzA5k3Jav",
        "colab_type": "text"
      },
      "source": [
        "* Generate the model and compile it.\n",
        "* Summary should provide information about the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJJfmZFY5bvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50(input_shape=(161,99,1),num_classes=12)\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ_LeCO33N2-",
        "colab_type": "text"
      },
      "source": [
        "* Generate the class weights.\n",
        "* This is needed as the unknown category contains significantly more files than the other categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN50W7o55fIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_integers = np.argmax(Y_train, axis=1)\n",
        "class_weights = compute_class_weight('balanced', np.unique(Y_integers), Y_integers)\n",
        "d_class_weights = dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8LHsxJ3Wb6",
        "colab_type": "text"
      },
      "source": [
        "* Train the deep learning model over the default settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxcM7u3D5n7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train_scaled,Y_train,epochs=20,validation_data=(X_val_scaled,Y_val),\n",
        "                    batch_size=128,shuffle=True,class_weight=d_class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpOugnlK3ZTP",
        "colab_type": "text"
      },
      "source": [
        "* Save the model to your working directory.\n",
        "* This will prevent you from having to restart training incase of error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaCBS1Cyt4WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"ResNet_Trained.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPabqeXY3fn_",
        "colab_type": "text"
      },
      "source": [
        "* If you do not need to reload the model you can skip this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ9pdGb-vjYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Trained_Models/ResNet_Trained.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCK955RJ3kUI",
        "colab_type": "text"
      },
      "source": [
        "* Code to plot the accuracy of the training and validation sets during model training.\n",
        "* Will save to a PDF figure in the working environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQaxBZUERS-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='bottom right')\n",
        "fig = plt.gcf()\n",
        "fig.savefig(\"CNN_fvocab_acc.pdf\",bbox_inches = \"tight\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpbmNvzc3pe4",
        "colab_type": "text"
      },
      "source": [
        "* Code to plot the loss of the training and validation sets during model training.\n",
        "* Will save to a PDF figure in the working environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45dAZdAqRWuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "fig = plt.gcf()\n",
        "fig.savefig(\"CNN_fvocab_loss.pdf\",bbox_inches = \"tight\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gXQd_fX3rVP",
        "colab_type": "text"
      },
      "source": [
        "* Load in part of the testing data that is generated in the pre-processing notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPWYM0yvxIz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = np.load(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/X_train_p1.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuUUVpb43zCC",
        "colab_type": "text"
      },
      "source": [
        "* Scale the pixels of the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23gnvvdzkXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = X1 * (1/255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB4t1s7I31Rk",
        "colab_type": "text"
      },
      "source": [
        "* Make predictions using the testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIw1JLPRxmfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_1 = model.predict(X1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAv5Nxj135V1",
        "colab_type": "text"
      },
      "source": [
        "* Repeat for the other parts of the testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWZnQKiZ296X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X1 = 0 to free up memory \n",
        "X1 = 0\n",
        "X2 = np.load(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/X_train_p2.npy\")\n",
        "X2 = X2 * (1/255)\n",
        "predict_2 = model.predict(X2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTtCxphf3H9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X2 = 0 to free up memory \n",
        "X2 = 0\n",
        "X3 = np.load(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/X_train_p3.npy\")\n",
        "X3 = X3 * (1/255)\n",
        "predict_3 = model.predict(X3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znfv5YS-4CJ0",
        "colab_type": "text"
      },
      "source": [
        "* Load in the .csv file for the filenames as a pandas dataframe.\n",
        "* This should contain the filenames for the testing data.\n",
        "* This is created in the testing pre-processing notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uTkTe3w6s_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_data = pd.read_csv(\"/content/drive/My Drive/Tensor_Flow_Speech_Recognition_Challenge/Data_Files/test/filenames.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7yO24Fr4O7p",
        "colab_type": "text"
      },
      "source": [
        "* Convert the predictions from the model to labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me_IWGKu7yNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class1 = np.argmax(predict_1,axis=1)\n",
        "predicted_class2 = np.argmax(predict_2,axis=1)\n",
        "predicted_class3 = np.argmax(predict_3,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvQ4D_Z_4UDs",
        "colab_type": "text"
      },
      "source": [
        "* Create a dictionary to map the labels to the correct voice command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce3WpbBAAFDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {\n",
        "    0 : \"yes\",\n",
        "    1 : \"no\",\n",
        "    2 : \"up\",\n",
        "    3 : \"down\",\n",
        "    4 : \"left\",\n",
        "    5 : \"right\",\n",
        "    6 : \"on\",\n",
        "    7 : \"off\",\n",
        "    8 : \"stop\",\n",
        "    9 : \"go\",\n",
        "    10 : \"silence\",\n",
        "    11 : \"unknown\"\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zt3nOpp4Y2w",
        "colab_type": "text"
      },
      "source": [
        "* Map the labels to the correct voice command.\n",
        "* Join the lists together to get the full list of predicted words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dijOdT8AzAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class_labels1 = [label_dict[k] for k in predicted_class1]\n",
        "predicted_class_labels2 = [label_dict[k] for k in predicted_class2]\n",
        "predicted_class_labels3 = [label_dict[k] for k in predicted_class3]\n",
        "\n",
        "predicted_class_label = predicted_class_labels1 + predicted_class_labels2 + predicted_class_labels3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NutbvGG4gag",
        "colab_type": "text"
      },
      "source": [
        "* Create a new column in the dataframe called \"label\" which we will fill with the predicted words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p61dYl0y7kuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_data[\"label\"] = np.nan\n",
        "\n",
        "output_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GX60iHS4mSG",
        "colab_type": "text"
      },
      "source": [
        "* Fill the \"label\" column with the predicted words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwvpmAL9CElo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class_array = np.asarray(predicted_class_label)\n",
        "print(predicted_class_array)\n",
        "\n",
        "output_data[\"label\"] = predicted_class_array\n",
        "\n",
        "output_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9WfGSQs4rat",
        "colab_type": "text"
      },
      "source": [
        "* Remove the unamed axis from the filename.csv dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpoTS5uKDw9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_data = output_data.drop(\"Unnamed: 0\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMf1baqo4vVz",
        "colab_type": "text"
      },
      "source": [
        "* Check that the output is in the form of the Kaggle submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjLFQHvLE_OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLRJJpBH4yvQ",
        "colab_type": "text"
      },
      "source": [
        "* Export the output to a .csv file ensuring that index=False.\n",
        "* The file is now ready for submission to Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAqlx3zJELNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_data.to_csv(\"submission_resnet.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}