{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing - 6 Vocabulary <br>\n",
    "\n",
    "Author: Jamie McQuire <br>\n",
    "\n",
    "* This Python notebook provides the code for the pre-processing for the 6-word vocabulary dataset.\n",
    "* The code will translate all the audio files into log spectrograms.\n",
    "* The output of this Python notebook will be the data and labels for the training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from scipy.io import wavfile\n",
    "import csv\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the path to your own working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the working directory to the Data directory\n",
    "os.chdir(\"C:\\\\Users\\\\b9027741\\\\OneDrive - Newcastle University\\\\Masters\\\\Computer Science\\\\Machine_Learning_Project\\\\Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These are the labels that are specified for the 6-word vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels needed - using the 6 I have specified for the vocabulary\n",
    "labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This function will return the log spectrogram of an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the log spectrograms\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dataframe that can be used to keep the audio file name and the respective label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               file_name label\n",
      "0  004ae714_nohash_0.wav   yes\n",
      "1  004ae714_nohash_1.wav   yes\n",
      "2  00f0204f_nohash_0.wav   yes\n",
      "3  00f0204f_nohash_1.wav   yes\n",
      "4  00f0204f_nohash_2.wav   yes\n"
     ]
    }
   ],
   "source": [
    "#create a pandas dataframe that contains the file name and the respective label\n",
    "all_files = pd.DataFrame(columns=(\"file_name\",\"label\"))\n",
    "all_files = all_files.fillna(0)\n",
    "\n",
    "for label in labels:\n",
    "    files = os.listdir(\"train/audio/\" + label)\n",
    "    for file in files:\n",
    "        all_files = all_files.append({\n",
    "                    \"file_name\":file,\n",
    "                    \"label\":label\n",
    "                    },ignore_index=True)\n",
    "\n",
    "print(all_files.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The class counts appear to be balanced meaning that we will not have to use Keras class_weights.\n",
    "* Total file size is 14206."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes      2377\n",
      "no       2375\n",
      "up       2375\n",
      "right    2367\n",
      "down     2359\n",
      "left     2353\n",
      "Name: label, dtype: int64\n",
      "(14206, 2)\n"
     ]
    }
   ],
   "source": [
    "#print the class counts and total file size\n",
    "print(all_files[\"label\"].value_counts())\n",
    "print(all_files.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 10% of the total files are going to be used as a testing set.\n",
    "* The remaining files are going to be divided into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   file_name  label\n",
      "8572   a42a88ff_nohash_0.wav   down\n",
      "4098   bd8412df_nohash_1.wav     no\n",
      "14004  eb0676ec_nohash_0.wav  right\n",
      "7562   33f60c62_nohash_0.wav   down\n",
      "12213  2f813234_nohash_1.wav  right\n",
      "                file_name label\n",
      "4   00f0204f_nohash_2.wav   yes\n",
      "5   012c8314_nohash_0.wav   yes\n",
      "9   0132a06d_nohash_3.wav   yes\n",
      "55  05b2db80_nohash_2.wav   yes\n",
      "64  06a79a03_nohash_0.wav   yes\n",
      "training_files shape: (12785, 2)\n",
      "test_files shape: (1421, 2)\n"
     ]
    }
   ],
   "source": [
    "training_files = all_files.sample(frac=0.9,random_state=42)\n",
    "test_files = all_files.drop(training_files.index)\n",
    "\n",
    "print(training_files.head())\n",
    "print(test_files.head())\n",
    "\n",
    "print(\"training_files shape: \" + str(training_files.shape))\n",
    "print(\"test_files shape: \" + str(test_files.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20% of the remaining files are going to be used as a validation set.\n",
    "* The remaining files will form the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   file_name label\n",
      "3438   78884794_nohash_2.wav    no\n",
      "10731  8c7c9168_nohash_2.wav  left\n",
      "9682   19f9c115_nohash_0.wav  left\n",
      "321    24befdb3_nohash_2.wav   yes\n",
      "6140   9886d8bf_nohash_4.wav    up\n",
      "1775   c22d3f18_nohash_0.wav   yes\n",
      "5197   333784b7_nohash_1.wav    up\n",
      "1932   d1214f15_nohash_1.wav   yes\n",
      "1397   9a7c1f83_nohash_1.wav   yes\n",
      "2361   fde2dee7_nohash_0.wav   yes\n",
      "                   file_name  label\n",
      "4098   bd8412df_nohash_1.wav     no\n",
      "12213  2f813234_nohash_1.wav  right\n",
      "3233   64da5281_nohash_2.wav     no\n",
      "8757   b83c1acf_nohash_3.wav   down\n",
      "7495   2bfe70ef_nohash_0.wav   down\n",
      "training_files shape: (10228, 2)\n",
      "validation_files shape: (2557, 2)\n"
     ]
    }
   ],
   "source": [
    "#train / validation split\n",
    "\n",
    "train_files = training_files.sample(frac=0.8,random_state=42)\n",
    "validation_files = training_files.drop(train_files.index)\n",
    "\n",
    "print(train_files.head(10))\n",
    "print(validation_files.head())\n",
    "\n",
    "print(\"training_files shape: \" + str(train_files.shape))\n",
    "print(\"validation_files shape: \" + str(validation_files.shape))\n",
    "\n",
    "#we now have the train/validation and test split needed\n",
    "#train_files\n",
    "#validation_files\n",
    "#test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This function will return the log spectrogram of a .wav file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2spec(wav_name,directory):\n",
    "    \n",
    "    sample_rate, samples = wavfile.read(directory + wav_name)\n",
    "    \n",
    "    #padding included but dont think it will be needed\n",
    "    if (len(samples) < 16000):\n",
    "        samples = np.pad(samples, (0, (16000 - len(samples))), \"linear_ramp\")\n",
    "    \n",
    "    _, spectrogram = log_specgram(samples,sample_rate)\n",
    "    \n",
    "    return spectrogram.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This function will return the data files values and labels.\n",
    "* This function is going to be used for the training, validation, and testing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(files,directory=\"train/audio/\"):\n",
    "    X = np.zeros([files.shape[0],161,99])\n",
    "    Y = np.zeros([files.shape[0]])\n",
    "    index = 0\n",
    "    for ind, row in files.iterrows():\n",
    "        try:\n",
    "            X[index] = wav2spec(row[\"file_name\"],directory+row[\"label\"]+\"/\")\n",
    "        except ValueError:\n",
    "            print(row,ValueError)\n",
    "        Y[index] = labels.index(row[\"label\"])\n",
    "        index += 1\n",
    "        \n",
    "    return X, Y\n",
    "    \n",
    "X_train, Y_train = create_data(train_files)\n",
    "X_val, Y_val = create_data(validation_files)\n",
    "X_test, Y_test = create_data(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the files to a directory on your personal computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data ready for the analysis\n",
    "np.save(\"train/data/X_train\", np.expand_dims(X_train,-1)+1.3)\n",
    "np.save(\"train/data/Y_train\",Y_train.astype(np.int))\n",
    "np.save(\"train/data/X_val\",np.expand_dims(X_val,-1)+1.3)\n",
    "np.save(\"train/data/Y_val\",Y_val.astype(np.int))\n",
    "np.save(\"train/data/X_test\",np.expand_dims(X_test,-1)+1.3)\n",
    "np.save(\"train/data/Y_test\",Y_test.astype(np.int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
