{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing - Full Vocabulary <br>\n",
    "\n",
    "Author: Jamie McQuire <br>\n",
    "\n",
    "* This Python notebook provides the code for the pre-processing for the full vocabulary dataset.\n",
    "* The code will generate audio files to represent silence.\n",
    "* The code will translate all the audio files into log spectrograms.\n",
    "* The output of this Python notebook will be the data and labels for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from scipy.io import wavfile\n",
    "import csv\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the path to your own working directory for reproducible analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the working directory to the Data directory\n",
    "os.chdir(\"C:\\\\Users\\\\b9027741\\\\OneDrive - Newcastle University\\\\Masters\\\\Computer Science\\\\Machine_Learning_Project\\\\Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The labels that are present in the validation set are listed below.\n",
    "* Any of the other folder labels that are not present in this list are going to be classed as unknown (excluding _background_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels needed\n",
    "labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Silence Audio\n",
    "\n",
    "* The silence class is currently empty and it is up to us to create files that can replicate silence.\n",
    "* The _background_noise_ folder only has 6 files in it.\n",
    "* We can split the audio files from the background noise into 1 second chunks and then add random gaussian noise to the data. This will create more silence audio files that can be used to train the machine learning algorithms.\n",
    "* This in principle could generate an infinite number of silence samples used to train the algorithms but due to computational restrictions we will limit this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b9027741\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "#create the silence data files\n",
    "def create_silence_audio():\n",
    "    for file in os.listdir(\"train/audio/_background_noise_/\"):\n",
    "        if \"wav\" in file:\n",
    "            sample_rate, audio = wavfile.read(\"train/audio/_background_noise_/\"+ file)\n",
    "            signal_arr = np.split(audio,np.arange(16000,len(audio),16000))\n",
    "            for index, sig_arr in enumerate(signal_arr):\n",
    "                for j in range(0,11):\n",
    "                    signal_plus_noise = sig_arr + np.random.normal(0,1,len(sig_arr))\n",
    "                    data=np.int16(signal_plus_noise/np.max(np.abs(signal_plus_noise)) * 32767)\n",
    "                    filename = \"noisy%d\" %j + \"_part%d\" %index + \"_%s\" %file\n",
    "                    wavfile.write(\"train/audio/silence/\"+filename,16000,signal_plus_noise)\n",
    "                \n",
    "create_silence_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Log-Spectrogram\n",
    "\n",
    "* This spectrogram will convert our sound data into a 2D image data using a fast fourier transform (FFT).\n",
    "* The function will return the frequencies and the log spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Order the folder labels so that we can classify the unknown categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'bed', 'bird', 'cat', 'dog', 'eight', 'five', 'four', 'happy', 'house', 'marvin', 'nine', 'one', 'seven', 'sheila', 'six', 'three', 'tree', 'two', 'wow', 'zero']\n"
     ]
    }
   ],
   "source": [
    "folder_labels = os.listdir(\"train/audio/\")\n",
    "folder_labels.remove(\"_background_noise_\")\n",
    "\n",
    "all_labels = [x for x in labels]\n",
    "\n",
    "for label in folder_labels:\n",
    "    if label not in all_labels:\n",
    "        all_labels.append(label)\n",
    "    \n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the validation list and add silence files into the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6798\n",
      "8406\n",
      "silence/noisy9_part9_dude_miaowing.wav\n"
     ]
    }
   ],
   "source": [
    "with open(\"train/validation_list.txt\") as validation_list:\n",
    "    validation_list = [row[0] for row in csv.reader(validation_list)]\n",
    "    \n",
    "print(len(validation_list))\n",
    "\n",
    "for i, file in enumerate(os.listdir(\"train/audio/silence\")):\n",
    "    if i%5 == 0:\n",
    "        validation_list.append(\"silence/\"+file)\n",
    "\n",
    "print(len(validation_list))\n",
    "\n",
    "print(validation_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the training list, a list of all of the files, and a dictionary of label counts that show how many instances of each word we have in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 2376, 'no': 2374, 'up': 2374, 'down': 2358, 'left': 2352, 'right': 2366, 'on': 2366, 'off': 2356, 'stop': 2379, 'go': 2371, 'silence': 8039, 'bed': 1712, 'bird': 1730, 'cat': 1732, 'dog': 1745, 'eight': 2351, 'five': 2356, 'four': 2371, 'happy': 1741, 'house': 1749, 'marvin': 1745, 'nine': 2363, 'one': 2369, 'seven': 2376, 'sheila': 1733, 'six': 2368, 'three': 2355, 'tree': 1732, 'two': 2372, 'wow': 1744, 'zero': 2375}\n"
     ]
    }
   ],
   "source": [
    "training_list = []\n",
    "all_files = []\n",
    "label_counts = {}\n",
    "\n",
    "for label in all_labels:\n",
    "    files = os.listdir(\"train/audio/\" + label)\n",
    "    for i, file in enumerate(files):\n",
    "        all_files.append(label + \"/\" + file)\n",
    "        file_path = label + \"/\" + file\n",
    "        if file_path not in validation_list:\n",
    "            training_list.append(file_path)\n",
    "        label_counts[label] = i\n",
    "        \n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Function to transform an audio file into a spectrogram.\n",
    "* Return the spectrogram as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2spec(wav_name,directory):\n",
    "    \n",
    "    sample_rate, samples = wavfile.read(directory + wav_name)\n",
    "    \n",
    "    if (len(samples) < 16000):\n",
    "        samples = np.pad(samples, (0, (16000 - len(samples))), \"linear_ramp\")\n",
    "    \n",
    "    _, spectrogram = log_specgram(samples,sample_rate)\n",
    "    \n",
    "    return spectrogram.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Function to create the training and validation datasets.\n",
    "* Return the numpy arrays for the data and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 yes/004ae714_nohash_0.wav\n",
      "2000 yes/f2a90886_nohash_0.wav\n",
      "4000 no/e32ff49d_nohash_1.wav\n",
      "6000 up/d8ee4734_nohash_1.wav\n",
      "8000 down/cb8f8307_nohash_6.wav\n",
      "10000 left/c1eebc0b_nohash_1.wav\n",
      "12000 right/b93528e3_nohash_0.wav\n",
      "14000 on/a8688b67_nohash_0.wav\n",
      "16000 off/96ab6565_nohash_2.wav\n",
      "18000 stop/8eb4a1bf_nohash_0.wav\n",
      "20000 go/7cf14c54_nohash_0.wav\n",
      "22000 silence/noisy11_part57_pink_noise.wav\n",
      "24000 silence/noisy18_part0_dude_miaowing.wav\n",
      "26000 silence/noisy5_part22_white_noise.wav\n",
      "28000 bed/531a5b8a_nohash_1.wav\n",
      "30000 bird/9e46cfa1_nohash_0.wav\n",
      "32000 cat/e4200516_nohash_0.wav\n",
      "34000 eight/2197f41c_nohash_1.wav\n",
      "36000 five/130d9a87_nohash_2.wav\n",
      "38000 four/0137b3f4_nohash_3.wav\n",
      "40000 four/f4c77b26_nohash_0.wav\n",
      "42000 house/3ab9ba07_nohash_0.wav\n",
      "44000 marvin/83957201_nohash_0.wav\n",
      "46000 nine/953fe1ad_nohash_1.wav\n",
      "48000 one/8549f25d_nohash_0.wav\n",
      "50000 seven/74b73f88_nohash_0.wav\n",
      "52000 sheila/85834399_nohash_1.wav\n",
      "54000 six/9aa21fa9_nohash_1.wav\n",
      "56000 three/92a9c5e6_nohash_3.wav\n",
      "58000 tree/ab5d7179_nohash_0.wav\n",
      "60000 two/b43de700_nohash_1.wav\n",
      "62000 wow/d85270c1_nohash_1.wav\n",
      "64000 zero/d1214f15_nohash_0.wav\n"
     ]
    }
   ],
   "source": [
    "def create_data_sets(file_list,directory):\n",
    "    X = np.zeros([len(file_list),161,99])\n",
    "    Y = np.zeros([len(file_list)])\n",
    "    for index, file in enumerate(file_list):\n",
    "        if index%2000 == 0:\n",
    "            print(index,file)\n",
    "        try:\n",
    "            X[index] = wav2spec(file,directory)\n",
    "        except ValueError:\n",
    "            print(index,file,ValueError)\n",
    "        Y[index] = all_labels.index(file.rsplit(\"/\")[0])\n",
    "        \n",
    "    return X, Y\n",
    "    \n",
    "X_train, Y_train = create_data_sets(training_list,\"train/audio/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This will give assign a categorical number to the (word) labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      "(64355, 161, 99)\n",
      "(64355,)\n"
     ]
    }
   ],
   "source": [
    "#all of the unknown values are 11\n",
    "#where < 11 else Y_train = 11\n",
    "Y_train = np.where(Y_train < 11, Y_train, 11)\n",
    "\n",
    "#test this and see that it works\n",
    "print(np.unique(Y_train))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This will repeat the same process and create the validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bed/026290a7_nohash_0.wav\n",
      "2000 happy/2296b1af_nohash_1.wav\n",
      "4000 right/099d52ad_nohash_1.wav\n",
      "6000 up/ad63d93c_nohash_0.wav\n",
      "8000 silence/noisy4_part88_doing_the_dishes.wav\n",
      "(8406, 161, 99)\n",
      "(8406,)\n"
     ]
    }
   ],
   "source": [
    "X_val, Y_val = create_data_sets(validation_list,\"train/audio/\")\n",
    "\n",
    "Y_val = np.where(Y_val < 11, Y_val, 11)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the training and validation sets to a directory of your choosing to replicate the analysis.\n",
    "* The expand_dims will include the channel dimension for keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data ready for the analysis\n",
    "np.save(\"train/data/X_train\", np.expand_dims(X_train,-1)+1.3)\n",
    "np.save(\"train/data/Y_train\",Y_train.astype(np.int))\n",
    "np.save(\"train/data/X_val\",np.expand_dims(X_val,-1)+1.3)\n",
    "np.save(\"train/data/Y_val\",Y_val.astype(np.int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
